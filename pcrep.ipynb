{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCR report Work In Progress :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pcrep.parse_input import parse_analysis_filepath\n",
    "from pcrep.constants import CONC_NAME, DIL_FINAL_FACTOR_NAME, DIL_TYPE_NAME, DIL_SAMPLE_DESCRIPTION_NAME\n",
    "\n",
    "INPUT_PCR_DATA = \"./example/231108_GN004773-019/230811_GN004773-019_20230811_100101_999.csv\"\n",
    "CONFIG_DIR = \"C:/work/pcr-report/data\"\n",
    "df = pd.read_csv(INPUT_PCR_DATA, delimiter=';', decimal=',')\n",
    "# df = df.replace(',', '.', regex=True)\n",
    "df[CONC_NAME] = df[CONC_NAME].astype('Float64')\n",
    "\n",
    "parsedc = parse_analysis_filepath(INPUT_PCR_DATA)\n",
    "ANALYSIS_DIR = parsedc['analysis_dir']\n",
    "\n",
    "BASE_FILEPATH = os.path.join(\n",
    "    ANALYSIS_DIR, '{}_{}'.format(parsedc['date'], parsedc['gn']))\n",
    "display(ANALYSIS_DIR)\n",
    "display(BASE_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CONCENTRATION_DATA = BASE_FILEPATH + '_conc.csv'\n",
    "df_conc = pd.read_csv(INPUT_CONCENTRATION_DATA, sep=\";\", decimal=',')\n",
    "\n",
    "df_conc.set_index(['sample_id'], inplace=True)\n",
    "df_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcrep.constants import FDL_NAME, SAMPLE_NAME, SAMPLE_TYPE_NAME, SAMPLE_NUM_NAME\n",
    "\n",
    "\n",
    "\n",
    "df.loc[:, [FDL_NAME]] = df[SAMPLE_NUM_NAME].map(\n",
    "    df_conc[DIL_FINAL_FACTOR_NAME], na_action='ignore')\n",
    "\n",
    "\n",
    "\n",
    "df.loc[:, [SAMPLE_NAME]] = df[SAMPLE_NUM_NAME].map(\n",
    "    df_conc[DIL_SAMPLE_DESCRIPTION_NAME], na_action='ignore')\n",
    "\n",
    "\n",
    "\n",
    "df.loc[:, [SAMPLE_TYPE_NAME]] = df[SAMPLE_NUM_NAME].map(\n",
    "    df_conc[DIL_TYPE_NAME], na_action='ignore')\n",
    "\n",
    "\n",
    "\n",
    "df = df.dropna(subset=[SAMPLE_TYPE_NAME])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df['Target'].unique()\n",
    "display(targets)\n",
    "samples = df['Sample description 1'].unique()\n",
    "samples.sort()\n",
    "display(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcrep.constants import WELL_RESULT_NAME\n",
    "from pcrep.pcrep import result_fn\n",
    "\n",
    "\n",
    "\n",
    "df.loc[:, [WELL_RESULT_NAME]] = df.apply(lambda x: result_fn(\n",
    "    x['Conc(copies/µL)'], x['final dilution factor']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLASMID_CONTROL_LIMITS_FILE = 'plasmid_control_limits.csv'\n",
    "palsmid_control_limits = pd.read_csv(\n",
    "    os.path.join(CONFIG_DIR, PLASMID_CONTROL_LIMITS_FILE))\n",
    "palsmid_control_limits.set_index(['Target'], inplace=True)\n",
    "palsmid_control_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE_CONTROL_LIMITS_FILE = 'reference_control_limits.csv'\n",
    "reference_control_limits = pd.read_csv(\n",
    "    os.path.join(CONFIG_DIR, REFERENCE_CONTROL_LIMITS_FILE))\n",
    "reference_control_limits.set_index(['Target'], inplace=True)\n",
    "reference_control_limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to access limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcl = reference_control_limits\n",
    "lmts = rcl.loc['IDT']\n",
    "lmts['upper 3s action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_limits = pd.read_csv('./data/method_limits.csv')\n",
    "method_limits.set_index(['target_id'], inplace=True)\n",
    "display(method_limits)\n",
    "\n",
    "dc_limits = {'method': method_limits, 'reference_control': reference_control_limits,\n",
    "             'plasmid_control': palsmid_control_limits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_limits.loc['IDT']['Lower [vg/μl]']\n",
    "mlmts = method_limits.loc['IDT']\n",
    "mlmts['Lower [vg/μl]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiindex ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = df.copy()\n",
    "dfi.reset_index(inplace=True)\n",
    "dfi.rename(columns={'Sample description 1': 'sample_id'}, inplace=True)\n",
    "dfi.set_index(['sample_id', 'Target', 'Well'], inplace=True)\n",
    "dfi.sort_index(inplace=True)\n",
    "dfi.sort_index(axis=1)\n",
    "dfi.drop(['Sample description 2', 'Sample description 3', 'Sample description 4',\n",
    "          'TargetType', 'Supermix', 'Status', 'Experiment', 'SampleType'],\n",
    "         axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute mean and standard deviation of `[vg/ml]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.loc[:, ['mean [vg/ml]']\n",
    "        ] = dfi.groupby(level=[\"sample_id\", 'Target']).apply(lambda x: x['vg/ml'].mean())\n",
    "\n",
    "dfi.loc[:, ['STDE']] = dfi.groupby(level=[\"sample_id\", 'Target']).apply(\n",
    "    lambda x: x['vg/ml'].std(ddof=0))\n",
    "# dfi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_fn(mean_vam: float, std_val: float, stype: str):\n",
    "    cv = float(\"nan\")\n",
    "    # cv is not applied to negative samples\n",
    "    if stype == 'nc':\n",
    "        return cv\n",
    "\n",
    "    if isinstance(mean_vam, float) and mean_vam != 0.0:\n",
    "        cv = 100.0 * std_val / mean_vam\n",
    "    return cv\n",
    "\n",
    "\n",
    "CV_COLNAME = 'CV [%]'\n",
    "dfi.loc[:, [CV_COLNAME]] = dfi.apply(lambda x: cv_fn(\n",
    "    x['mean [vg/ml]'], x['STDE'], x['sample type']), axis=1)\n",
    "dfi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcrep.check import method_check_routing\n",
    "\n",
    "METHOD_CHECK_COLNAME = 'Conc(copies/µL)'\n",
    "\n",
    "\n",
    "def method_check_fn(s):\n",
    "    return method_check_routing(dc_limits['method'], s[SAMPLE_TYPE_NAME],\n",
    "                                s[METHOD_CHECK_COLNAME], s.name[1])\n",
    "\n",
    "\n",
    "VALUE_CHECK_NAME = 'method_check'\n",
    "dfi.loc[:, [VALUE_CHECK_NAME]] = dfi.apply(\n",
    "    lambda x: method_check_fn(x), axis=1)\n",
    "dfi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droplets check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcrep.check import droplets_check\n",
    "\n",
    "DROPLET_THRESHOLD = int(10000)\n",
    "DROPLET_CHECK_COLNAME = 'Accepted Droplets'\n",
    "\n",
    "\n",
    "def droplets_check_fn(s):\n",
    "    return droplets_check(s[DROPLET_CHECK_COLNAME], DROPLET_THRESHOLD)\n",
    "\n",
    "\n",
    "DROPLET_CHECK_NAME = 'droplet_check'\n",
    "dfi.loc[:, [DROPLET_CHECK_NAME]] = dfi.apply(\n",
    "    lambda x: droplets_check_fn(x), axis=1)\n",
    "dfi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcrep.check import control_check_routing\n",
    "\n",
    "CONTROL_CHECK_COLNAME_ORIG = 'mean [vg/ml]'\n",
    "\n",
    "\n",
    "def control_check_fn(s):\n",
    "    c = control_check_routing(dc_limits, s[SAMPLE_TYPE_NAME],\n",
    "                              s[CONTROL_CHECK_COLNAME_ORIG], s.name[1])\n",
    "    return c[0]\n",
    "\n",
    "\n",
    "def warning_check_fn(s):\n",
    "    c = control_check_routing(dc_limits, s[SAMPLE_TYPE_NAME],\n",
    "                              s[CONTROL_CHECK_COLNAME_ORIG], s.name[1])\n",
    "    return c[1]\n",
    "\n",
    "\n",
    "CONTROL_CHECK_NAME = 'control_check'\n",
    "dfi.loc[:, [CONTROL_CHECK_NAME]] = dfi.apply(\n",
    "    lambda x: control_check_fn(x), axis=1)\n",
    "\n",
    "WARNING_CHECK_NAME = 'warning_check'\n",
    "dfi.loc[:, [WARNING_CHECK_NAME]] = dfi.apply(\n",
    "    lambda x: warning_check_fn(x), axis=1)\n",
    "\n",
    "\n",
    "dfi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcrep.check import cv_check\n",
    "\n",
    "\n",
    "def cv_check_fn(cv_val: float):\n",
    "    return cv_check(cv_val)\n",
    "\n",
    "\n",
    "CV_CHECK_NAME = 'cv_check'\n",
    "dfi.loc[:, [CV_CHECK_NAME]] = dfi.apply(\n",
    "    lambda x: cv_check_fn(x[CV_COLNAME]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating point formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_comment(s, n):\n",
    "    if s and n:\n",
    "        s += ', ' + n\n",
    "    elif not s and n:\n",
    "        s = n\n",
    "    return s\n",
    "\n",
    "\n",
    "def concat_comments(x):\n",
    "    s = None\n",
    "    s = add_comment(s, x['method_check'])\n",
    "    s = add_comment(s, x['droplet_check'])\n",
    "    s = add_comment(s, x['control_check'])\n",
    "    s = add_comment(s, x['cv_check'])\n",
    "    s = add_comment(s, x['warning_check'])\n",
    "    return s\n",
    "\n",
    "\n",
    "dfi = dfi.assign(comments=dfi.apply(lambda x: concat_comments(x), axis=1))\n",
    "dfi\n",
    "dfc = dfi.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['Sample', 'final dilution factor', 'Conc(copies/µL)',\n",
    "             'vg/ml', 'mean [vg/ml]', 'STDE', 'CV [%]', 'comments',\n",
    "             'Accepted Droplets', 'Positives', 'Negatives', 'sample type']\n",
    "dfi = dfi.loc[:, col_order]\n",
    "dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_mapping = {'Conc(copies/µL)': '{:.2f}',\n",
    "                  'vg/ml': '{:.2e}',\n",
    "                  'mean [vg/ml]': '{:.2e}',\n",
    "                  'STDE': '{:.2e}',\n",
    "                  'CV [%]': '{:.2f}',\n",
    "                  'final dilution factor': '{:.0e}'\n",
    "                  }\n",
    "dff = dfi.style.format(format_mapping)\n",
    "display(dff)\n",
    "dff.to_excel(BASE_FILEPATH + '-data_analysis_raw.xlsx', engine='openpyxl')\n",
    "dfi.to_markdown(BASE_FILEPATH + '-data_analysis.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(\n",
    "    BASE_FILEPATH + '-data_analysis.xlsx', engine=\"xlsxwriter\")\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "dfi.to_excel(writer, sheet_name=\"Sheet1\")\n",
    "\n",
    "# Get the xlsxwriter workbook and worksheet objects.\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "\n",
    "# Add some cell formats.\n",
    "fmt_fdl = workbook.add_format({\"num_format\": \"0E+00\"})\n",
    "fmt_dec2e = workbook.add_format({\"num_format\": \"0.00E+00\"})\n",
    "fmt_dec2f = workbook.add_format({\"num_format\": \"0.00\"})\n",
    "\n",
    "# Note: It isn't possible to format any cells that already have a format such\n",
    "# as the index or headers or any cells that contain dates or datetimes.\n",
    "\n",
    "# Set the column width and format.\n",
    "worksheet.set_column('D:D', 32)\n",
    "worksheet.set_column('E:E', 18, fmt_fdl)\n",
    "worksheet.set_column('F:F', 14, fmt_dec2f)\n",
    "worksheet.set_column('G:I', 14, fmt_dec2e)\n",
    "worksheet.set_column('J:J', None, fmt_dec2f)\n",
    "worksheet.set_column('K:K', 32)\n",
    "worksheet.set_column('L:O', 16)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get sample..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(df, samnple_num, target_id=None):\n",
    "    idx = pd.IndexSlice\n",
    "    if target_id:\n",
    "        return df.loc[idx[samnple_num, target_id, :], :]\n",
    "    else:\n",
    "        return df.loc[idx[samnple_num, :, :], :]\n",
    "\n",
    "\n",
    "tmps = get_sample(dfi, 2)\n",
    "tmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = pd.IndexSlice\n",
    "tmps.loc[idxs[2, ['IDT'], :], :]['mean [vg/ml]'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "params_file = './data/params.json'\n",
    "with open(params_file) as json_file:\n",
    "    check_params = json.load(json_file)\n",
    "# print(check_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create final (MS Word) dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmps.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = pd.IndexSlice\n",
    "display(tmps.loc[idxs[2, ['IDT'], :], :]['mean [vg/ml]'].values[0])\n",
    "display(tmps.loc[idxs[2, ['IDT'], :], :]['Sample'].values[0])\n",
    "display(tmps.index[0])\n",
    "tmps.index.get_level_values('Target').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmps.index.get_level_values('sample_id').unique()[0]\n",
    "tmps['Sample'].array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "DC_CONTROLS = {'IDT': {True: 'valid', False: 'not valid'},\n",
    "               'ITR': {True: 'fulfill assay criteria', False: 'does not fulfill assay criteria'}}\n",
    "\n",
    "\n",
    "def add_to(first, second, delim):\n",
    "    if first:\n",
    "        return first + delim + second\n",
    "    elif second:\n",
    "        return second\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def isvalid_nc(s):\n",
    "    comment = None\n",
    "    val = s['mean [vg/ml]'].values[0]\n",
    "    target = s.index.get_level_values('Target')[0]\n",
    "    valid = not any(x is not None for x in s['droplet_check'].values)\n",
    "    if any(x is not None for x in s['droplet_check'].values):\n",
    "        comment = reduce(lambda s1, s2: s1 or s2, s['droplet_check'].values)\n",
    "        valid = False\n",
    "    if any(x is not None for x in s['method_check'].values):\n",
    "        comment = add_to(comment, reduce(\n",
    "            lambda s1, s2: s1 or s2, s['method_check'].values), '; ')\n",
    "        valid = False\n",
    "    # valid &= not any(x is not None for x in s['method_check'].values)\n",
    "    val = DC_CONTROLS[target][valid]\n",
    "\n",
    "    return (valid, val, comment)\n",
    "\n",
    "\n",
    "def isvalid_prs(s):\n",
    "    # display(s)\n",
    "    ret = s['mean [vg/ml]'].values[0]\n",
    "    comment = None\n",
    "    valid = True\n",
    "    if any(x is not None for x in s['droplet_check'].values):\n",
    "        comment = reduce(lambda s1, s2: s1 or s2, s['droplet_check'].values)\n",
    "        valid = False\n",
    "    if any(x is not None for x in s['method_check'].values):\n",
    "        comment = add_to(comment, reduce(\n",
    "            lambda s1, s2: s1 or s2, s['method_check'].values), '; ')\n",
    "        valid = False\n",
    "    if any(x is not None for x in s['cv_check'].values):\n",
    "        comment = add_to(comment, reduce(\n",
    "            lambda s1, s2: s1 or s2, s['cv_check'].values), '; ')\n",
    "        valid = False\n",
    "    if any(x is not None for x in s['warning_check'].values):\n",
    "        comment = add_to(comment, reduce(\n",
    "            lambda s1, s2: s1 or s2, s['warning_check'].values), '; ')\n",
    "\n",
    "    return (valid, ret, comment)\n",
    "\n",
    "\n",
    "def process_sample(s):\n",
    "    targets = s.index.get_level_values('Target').unique()\n",
    "    target = '/'.join(targets)\n",
    "    id = int(s.index.get_level_values('sample_id').unique()[0])\n",
    "    stype = s['sample type'].array[0]\n",
    "    dc = {'id': id,\n",
    "          'target': target,\n",
    "          'type': stype,\n",
    "          'name': s['Sample'].array[0]\n",
    "          }\n",
    "    for t in targets:\n",
    "        comment = None\n",
    "        k = f'result {t} [vg/ml]'\n",
    "        kc = f'comment {t}'\n",
    "        if stype == 'nc':\n",
    "            v = isvalid_nc(s.loc[idxs[:, [t], :], :])\n",
    "            if not v[0]:\n",
    "                comment = DC_CONTROLS[t][v[0]] + '; ' + v[2]\n",
    "            # else:\n",
    "            #     comment = DC_CONTROLS[t][v[0]]\n",
    "        elif stype == 'pc' or stype == 'rc':\n",
    "            v = isvalid_prs(s.loc[idxs[:, [t], :], :])\n",
    "            comment = DC_CONTROLS[t][v[0]]\n",
    "        elif stype == 's':\n",
    "            v = isvalid_prs(s.loc[idxs[:, [t], :], :])\n",
    "            if not v[0]:\n",
    "                v = (v[0], v[2])\n",
    "        dc[k] = v[1]\n",
    "        dc[kc] = comment\n",
    "    return dc\n",
    "\n",
    "\n",
    "dff = pd.DataFrame()\n",
    "for n in samples:\n",
    "    s = get_sample(dfc, n)\n",
    "    r = process_sample(s)\n",
    "    dff = pd.concat([dff, pd.DataFrame([r])], ignore_index=True)\n",
    "dff.set_index(['id'], inplace=True)\n",
    "\n",
    "col_order = ['target', 'type', 'name', 'result IDT [vg/ml]',\n",
    "             'result ITR [vg/ml]', 'comment IDT', 'comment ITR']\n",
    "dff = dff.loc[:, col_order]\n",
    "display(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(\n",
    "    BASE_FILEPATH + '-final.xlsx', engine=\"xlsxwriter\")\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "dff.to_excel(writer, sheet_name=\"Sheet1\")\n",
    "\n",
    "# Get the xlsxwriter workbook and worksheet objects.\n",
    "workbook = writer.book\n",
    "worksheet = writer.sheets[\"Sheet1\"]\n",
    "\n",
    "# Add some cell formats.\n",
    "fmt_dec2e = workbook.add_format({\"num_format\": \"0.00E+00\"})\n",
    "\n",
    "# Note: It isn't possible to format any cells that already have a format such\n",
    "# as the index or headers or any cells that contain dates or datetimes.\n",
    "\n",
    "# Set the column width and format.\n",
    "worksheet.set_column('D:D', 32)\n",
    "worksheet.set_column('E:E', 18, fmt_dec2e)\n",
    "worksheet.set_column('F:F', 24, fmt_dec2e)\n",
    "worksheet.set_column('G:G', 32)\n",
    "worksheet.set_column('H:H', 32)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = get_sample(dfc, 1)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown and word export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('md_intro.md', 'r') as f:\n",
    "#     md_intro = f.read()\n",
    "# with open('md_end.md', 'r') as f:\n",
    "#     md_end = f.read()\n",
    "\n",
    "# md_eval = final.to_markdown()\n",
    "\n",
    "# md = md_intro + md_eval + md_end\n",
    "\n",
    "\n",
    "# def save_md(file_path, md_txt):\n",
    "#     try:\n",
    "#         with open(file_path, 'w') as fl:\n",
    "#             fl.write(md_txt)\n",
    "#     except Exception as e:\n",
    "#         print('Error: ' + str(e))\n",
    "\n",
    "\n",
    "# MD_FILE = './example/230901_GN004308-086/230901_GN004308-086.md'\n",
    "# save_md(MD_FILE, md)\n",
    "\n",
    "# xls_path = os.path.splitext(MD_FILE)[0] + '.xlsx'\n",
    "# final.to_excel(xls_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pcrep import mdhandling\n",
    "\n",
    "# with open(os.path.join(DATA_DIR, \"config.json\")) as json_file:\n",
    "#     jd = json.load(json_file)\n",
    "#     reference_doc = jd['reference_docx']\n",
    "#     pdflatex_bin = jd['pdflatex_bin']\n",
    "#     pandoc_bin = jd['pandoc_bin']\n",
    "\n",
    "# mdhandling.md2docx(pandoc_bin, reference_doc, MD_FILE)\n",
    "# print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install jinja2\n",
    "# ! pip install tabulate\n",
    "# ! pip install xlsxwriter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
